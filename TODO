TODO

- [x] Add timeout in DB query
- [x] strip trailing / in Base URL arg before init new crawler, add leading / if not present in marked Urls
- [x] Add index to DB
- [x] modify db connection settings: max/min connections, etc
- [x] There might be a case when the marked url is different from url fetched from db, and db entry isMonitored is set to true, decide what2do -> saving both if same baseURL
- [x] extended href validation required, way to ignore urls -> list of strings to check if present, ignore
- [x] add flag to blacklist/whitelist urls based on 1) Content-Type, Content-Length header and 2) file extensions -> handled by ignore list
- [ ] make marked-url mandatory?; '*' as wildcard to fetch all pages?
- [x] maintain a ignored hash map
- [ ] implement models for SQLite v0.8.0
- [x] graceful exit v0.5.0
- [ ] write the web UI to view and manage 'URLs' and 'Pages' models v0.9.0
- [ ] scrolling logs v0.7.0
- [ ] write monitored urls to files v0.6.0
- [ ] parse website robots.txt, add disallow paths to ignore list v0.6.0
- [ ] take user agent from cmd args v0.6.0
